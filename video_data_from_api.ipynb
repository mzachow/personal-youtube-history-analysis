{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import datetime\n",
    "import isodate\n",
    "from urllib.parse import urlparse\n",
    "from apiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVELOPER_KEY = \"YOURAPIKEY\"\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "\n",
    "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)\n",
    "\n",
    "# The API has a rate limit per day, so that we store the result of previous days in results_vn\n",
    "df = pd.read_csv(\"DIRECTORY/youtube_clicks.csv\")\n",
    "results_v1 = pd.read_csv(\"DIRECTORY/results/result_v1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of unique video IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some videos I watched more often over the years so we do not need to waste API requests \n",
    "# in case I already extracted info about them\n",
    "done = results_v1.video_id.unique()\n",
    "videos = df[df.Video_ID.isin(done) == False].Video_ID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1408,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7213,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empty Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['video_id', \"categoryId\", 'duration', 'dimension', 'definition', 'caption', 'licensedContent', 'projection', 'publishedAt',\n",
    "               'description', 'tags', 'defaultAudioLanguage', 'viewCount', 'likeCount', 'dislikeCount', 'favoriteCount', 'commentCount']\n",
    "\n",
    "df_video = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get video info for each video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = [\"viewCount\", \"likeCount\", \"dislikeCount\", \"favoriteCount\", \"commentCount\"]\n",
    "snippet = [\"publishedAt\", \"description\", \"tags\", \"defaultAudioLanguage\", \"categoryId\"]\n",
    "content = [\"duration\", \"caption\", \"definition\", \"dimension\", \"licensedContent\", \"projection\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vid in videos:\n",
    "    \n",
    "    df_vid = pd.DataFrame(columns=column_names)\n",
    "    df_vid.video_id = pd.Series([vid])\n",
    "    \n",
    "    try:\n",
    "        response = youtube.videos().list(part='snippet, contentDetails, statistics', id=vid).execute()\n",
    "        df_vid[\"got_info\"] = \"yes\"\n",
    "    except:\n",
    "        df_vid[\"got_info\"] = \"no\"\n",
    "        continue\n",
    "         \n",
    "    for x in snippet:\n",
    "        try:\n",
    "            df_vid[x] = pd.Series([response['items'][0][\"snippet\"][x]])\n",
    "        except:\n",
    "            df_vid[x] = \"no data\"\n",
    "        \n",
    "    for x in content:\n",
    "        try:\n",
    "            df_vid[x] = pd.Series([response['items'][0][\"contentDetails\"][x]])\n",
    "        except:\n",
    "            df_vid[x] = \"no data\"\n",
    "    \n",
    "    for x in stats:\n",
    "            try:\n",
    "                df_vid[x] = pd.Series([response['items'][0][\"statistics\"][x]])\n",
    "            except:\n",
    "                df_vid[x] = \"no data\"\n",
    "    \n",
    "    \n",
    "    df_video = df_video.append(df_vid, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7213, 18)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe progress to be used at the end of all API requests\n",
    "df_video.to_csv(\"YOUR/DIRECTORY/video_info_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get videos from previous day\n",
    "df_video_v1 = pd.read_csv(\"YOUR/DIRECTORY/video_info_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2277, 18)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# videos_total holds video API info of all past request of the previous days\n",
    "videos_total = df_video_v1.append(df_video)\n",
    "videos_total.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join Video_ID Infos to Video_Clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now merge that API info to our click info (data watched, watched after search, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df, videos_total, how='left', left_on=['Video_ID'], right_on=[\"video_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And mark all those videos as done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[result.got_info == \"yes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"DIRECTORY/result_v2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn categoryID into category_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['', 'Film & Animation', 'Autos & Vehicles', '', '', '', '', '', '', '', 'Music', '', '', '', '', \n",
    "            'Pets & Animals', '', 'Sports', 'Short Movies', 'Travel & Events', 'Gaming', 'Videoblogging', \n",
    "              'People & Blogs', 'Comedy', 'Entertainment', 'News & Politics', 'Howto & Style', 'Education', \n",
    "              'Science & Technology', 'Nonprofits & Activism', 'Movies', 'Anime/Animation', 'Action/Adventure', \n",
    "              'Classics', 'Comedy', 'Documentary', 'Drama', 'Family', 'Foreign', 'Horror', 'Sci-Fi/Fantasy', 'Thriller', \n",
    "              'Shorts', 'Shows', 'Trailers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cat(x):\n",
    "    if (x != \"no data\") & (x != \"rate limit\") & (x != \"no category\"):\n",
    "        return categories[int(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_total[\"category_name\"] = videos_total[\"categoryId\"].apply(lambda x: find_cat(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert duration to Timedelta and get total Seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_total = pd.read_csv(\"PATH/TO/DIRECTORY/youtube_clicks_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_final = results_final[(results_final[\"duration\"] != \"no data\") & (results_final[\"duration\"]!= \"NaN\")]\n",
    "results_final[\"duration\"] = results_final[\"duration\"].apply(lambda x: isodate.parse_duration(x))\n",
    "results_final[\"duration in seconds\"] = results_final[\"duration\"].apply(lambda x: x.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203, 30)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_final[results_final.Year == 2016].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substract Clicked_Date from PublishedAt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Video_Title', 'Video_URL', 'Video_Channel', 'video_id', 'Video_Date',\n",
       "       'year', 'hour', 'month', 'dayofweek', 'category', 'category_name',\n",
       "       'caption', 'commentCount', 'defaultAudioLanguage', 'definition',\n",
       "       'description', 'dimension', 'dislikeCount', 'duration', 'favoriteCount',\n",
       "       'got_info', 'licensedContent', 'likeCount', 'projection', 'publishedAt',\n",
       "       'tags', 'viewCount', 'duration in seconds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_final[\"time_online_until_watched\"] = pd.to_datetime(results_final[\"Video_Date\"], utc=True) - \\\n",
    "                                    pd.to_datetime(results_final[\"publishedAt\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert time to days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_final[\"days_online_until_watched\"] = results_final[\"time_online_until_watched\"].apply(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_final = pd.read_csv(\"EXPORT/PATH/results/result_v6.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
